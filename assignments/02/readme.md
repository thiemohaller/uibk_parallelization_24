# Assignment 3

The goal of this assignment is to write your first MPI program.

## Description

Maybe you have already heard of **Fractals** or **Mandelbrot**. [Fractals](https://en.wikipedia.org/wiki/Fractal) are geometric patterns that appear to be infinitely detailed. There are many [functions](https://en.wikipedia.org/wiki/List_of_fractals_by_Hausdorff_dimension) that can generate such patterns. The more often you evaluate these functions, the more detailed the pattern becomes. 

This task will focus on the [Mandelbrot set](https://en.wikipedia.org/wiki/Mandelbrot_set), a set of complex numbers that is generated by the function *z<sub>n+1</sub>=z<sub>n</sub><sup>2</sup>+c*, where *z* is a complex number and *c* is a constant.
> Short reminder: a complex number *z* is the sum of a real part *x* and an imaginary part *y* that includes the imaginary unit *i* with the property (*i<sup>2</sup>=-1*) &rarr; *z=x+yi*.

## Tasks

- A sequential implementation is available in [mandelbrot_seq.cpp](mandelbrot_seq.cpp). Read the code and make sure you understand what happens. Run it in order to see what the generated image should look like. Note that the program uses modern C++ facilities, hence older compilers might have issues compiling this code. If you get any `chrono.h` errors on LCC3, make sure to load a more modern version of gcc first: `module load gcc/12.2.0-gcc-8.5.0-p4pe45v`
- Parallelize the implementation using MPI in `mandelbrot_mpi.cpp`. 
    1) make sure you initialize the MPI environment in the beginning and finalize the MPI environment at the end of your program
    2) add some output that prints the number of ranks and also the individual ID of each rank
    3) add some code for domain decomposition, i.e. subdividing the computed image into individual chunks for ranks to work on
    4) add some code for merging the individual chunks into a single, complete image
- Run it with varying numbers of ranks and problem sizes and verify its correctness by comparing the output to `mandelbrot_seq.cpp`.
- Make sure you use compiler optimizations.
- Discuss the effects and implications of your parallelization.
- Insert the measured wall time for 64 cores and a problem size of 3840x2160 into the comparison spreadsheet.
- How would you improve program performance?

## Hints

- You are free to choose how you compile the codes, but e.g. you can use `cmake` using the provided `CMakeLists.txt`:
  - load relatively modern versions of cmake, gcc and OpenMPI: `module load gcc/12.2.0-gcc-8.5.0-p4pe45v openmpi/3.1.6-gcc-12.2.0-d2gmn55`
  - compile the codes: `mkdir build && cd build && cmake .. -DCMAKE_BUILD_TYPE=Release`
  - done
