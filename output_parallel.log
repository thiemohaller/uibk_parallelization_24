 ning in parallel with 8 tasks 
 Created new tasks for rank 1
 MPI coordinates for rank 1 -> 0 0 1
---------------------- DEBUG GRID RANK 1----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: -0.5 -0.5 0
Upper Bound: 0 0 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 1----------------------
 Created new tasks for rank 2
 MPI coordinates for rank 2 -> 0 1 0
---------------------- DEBUG GRID RANK 2----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: -0.5 0 -0.5
Upper Bound: 0 0.5 0
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 2----------------------
 Created new tasks for rank 3
 MPI coordinates for rank 3 -> 0 1 1
---------------------- DEBUG GRID RANK 3----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: -0.5 0 0
Upper Bound: 0 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 3----------------------
 Created new tasks for rank 4
 MPI coordinates for rank 4 -> 1 0 0
---------------------- DEBUG GRID RANK 4----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: 0 -0.5 -0.5
Upper Bound: 0.5 0 0
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 4----------------------
 Created new tasks for rank 5
 MPI coordinates for rank 5 -> 1 0 1
---------------------- DEBUG GRID RANK 5----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: 0 -0.5 0
Upper Bound: 0.5 0 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 5----------------------
 Created new tasks for rank 6
 MPI coordinates for rank 6 -> 1 1 0
---------------------- DEBUG GRID RANK 6----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: 0 0 -0.5
Upper Bound: 0.5 0.5 0
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 6----------------------
 Created new tasks for rank 7
 MPI coordinates for rank 7 -> 1 1 1
---------------------- DEBUG GRID RANK 7----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: 0 0 0
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 7----------------------
 Created new tasks for rank 0
 MPI coordinates for rank 0 -> 0 0 0
---------------------- DEBUG GRID RANK 0----------------------
Global Grid Information:
Number of Cells: 128 128 128
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0.5 0.5 0.5
Cell Size: 0.0078125 0.0078125 0.0078125
----
Local Grid Information:
Number of Cells: 64 64 64
Lower Bound: -0.5 -0.5 -0.5
Upper Bound: 0 0 0
Cell Size: 0.0078125 0.0078125 0.0078125
---------------------- end of DEBUG GRID RANK 0----------------------
 resizing field 0:
 resizing field 0:
 Volume of Sedov region: 0.00416946 in 8744 cells
 resizing field 0:
 resizing field 0:
 resizing field 0:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 resizing field 0:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 resizing field 0:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 resizing field 0:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
Rank 6 is applying boundary conditions in parallel
Rank 2 is applying boundary conditions in parallel
Rank 0 is applying boundary conditions in parallel
Rank 4 is applying boundary conditions in parallel
Rank 1 is applying boundary conditions in parallel
Rank 3 is applying boundary conditions in parallel
[n001:3080479:0:3080479] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7fffe99a3368)
[n001:3080477:0:3080477] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7ffd2b1ba388)
[n001:3080481:0:3080481] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7fff7a07b268)
[n001:3080483:0:3080483] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7fffb5e46968)
Rank 5 is applying boundary conditions in parallel
Rank 7 is applying boundary conditions in parallel
==== backtrace (tid:3080481) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x0000000000409d87 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040d1a6 finite_volume_solver::run()  ???:0
12 0x0000000000403f2d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040439e _start()  ???:0
=================================
==== backtrace (tid:3080483) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x0000000000409d87 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040d1a6 finite_volume_solver::run()  ???:0
12 0x0000000000403f2d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040439e _start()  ???:0
=================================
==== backtrace (tid:3080477) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x0000000000409d87 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040d1a6 finite_volume_solver::run()  ???:0
12 0x0000000000403f2d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040439e _start()  ???:0
=================================
==== backtrace (tid:3080479) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x0000000000409d87 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040d1a6 finite_volume_solver::run()  ???:0
12 0x0000000000403f2d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040439e _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 2 with PID 3080479 on node n001 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
Command exited with non-zero status 139
	Command being timed: "mpiexec -n 8 ./code_parallel/build/apps/run_full_code.parallel"
	User time (seconds): 0.09
	System time (seconds): 0.08
	Percent of CPU this job got: 36%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.51
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 45020
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 134
	Minor (reclaiming a frame) page faults: 8902
	Voluntary context switches: 883
	Involuntary context switches: 27
	Swaps: 0
	File system inputs: 0
	File system outputs: 8
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 139
