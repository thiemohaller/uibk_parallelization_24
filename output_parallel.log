 I am using rank 1 of 8
 I am using rank 5 of 8
 I am using rank 7 of 8
 I am using rank 3 of 8
 I am using rank 4 of 8
 I am using rank 6 of 8
 I am using rank 0 of 8
 ning in parallel with 8 tasks 
 Created new tasks for rank 0
 MPI coordinates for rank 0 -> 0 0 0
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Anfang: -0.496094 -0.5
 Ende: -0.00390625 0
 I am using rank 2 of 8
 Created new tasks for rank 2
 MPI coordinates for rank 2 -> 0 1 0
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Anfang: -0.496094 -0.5
 Ende: -0.00390625 0
 Created new tasks for rank 7
 MPI coordinates for rank 7 -> 1 1 1
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Anfang: 0.00390625 0
 Ende: 0.496094 0.5
 Created new tasks for rank 3
 MPI coordinates for rank 3 -> 0 1 1
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Anfang: -0.496094 -0.5
 Ende: -0.00390625 0
 Created new tasks for rank 1
 MPI coordinates for rank 1 -> 0 0 1
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Anfang: -0.496094 -0.5
 Ende: -0.00390625 0
 Created new tasks for rank 4
 MPI coordinates for rank 4 -> 1 0 0
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Anfang: 0.00390625 0
 Ende: 0.496094 0.5
 Created new tasks for rank 5
 MPI coordinates for rank 5 -> 1 0 1
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Anfang: 0.00390625 0
 Ende: 0.496094 0.5
 Created new tasks for rank 6
 MPI coordinates for rank 6 -> 1 1 0
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from -0.5 0.5 with 128 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from 0 0.5 with 64 cells
 Making linear grid from -0.5 0 with 64 cells
 Anfang: 0.00390625 0
 Ende: 0.496094 0.5
 Volume of Sedov region: 0.00416946 in 8744 cells
 resizing field 0:
 resizing field 0:
 resizing field 0:
 resizing field 0:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 1:
 resizing field 0:
 resizing field 0:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 1:
 resizing field 0:
 -> 314432
 resizing field 1:
 resizing field 0:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 resizing field 1:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 2:
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 resizing field 3:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 resizing field 4:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 -> 314432
 resizing field 5:
 -> 314432
 resizing field 5:
 -> 314432
 -> 314432
 -> 314432
[n001:3067957:0:3067957] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7ffd605d3208)
[n001:3067959:0:3067959] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7ffef558b978)
[n001:3067961:0:3067961] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7ffed3dd1fd8)
[n001:3067963:0:3067963] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x7ffd83062868)
==== backtrace (tid:3067961) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x00000000004096b4 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040cb16 finite_volume_solver::run()  ???:0
12 0x000000000040407d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040447e _start()  ???:0
=================================
==== backtrace (tid:3067959) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x00000000004096b4 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040cb16 finite_volume_solver::run()  ???:0
12 0x000000000040407d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040447e _start()  ???:0
=================================
==== backtrace (tid:3067957) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x00000000004096b4 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040cb16 finite_volume_solver::run()  ???:0
12 0x000000000040407d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040447e _start()  ???:0
=================================
==== backtrace (tid:3067963) ====
 0 0x00000000000534e9 ucs_debug_print_backtrace()  ???:0
 1 0x0000000000012cf0 __funlockfile()  :0
 2 0x0000000000037005 __memcpy_sse2_unaligned_erms()  :0
 3 0x00000000000248a3 ucp_dt_pack()  ???:0
 4 0x000000000002e6b2 ucp_tag_offload_unexp_eager()  ???:0
 5 0x00000000000148e9 uct_mm_ep_am_bcopy()  ???:0
 6 0x000000000002e9c9 ucp_tag_offload_unexp_eager()  ???:0
 7 0x000000000003aa0e ucp_tag_send_nbr()  ???:0
 8 0x00000000001a68b1 mca_pml_ucx_send()  ???:0
 9 0x00000000000b2d1d PMPI_Sendrecv()  ???:0
10 0x00000000004096b4 finite_volume_solver::apply_boundary_conditions()  ???:0
11 0x000000000040cb16 finite_volume_solver::run()  ???:0
12 0x000000000040407d main()  ???:0
13 0x000000000003ad85 __libc_start_main()  ???:0
14 0x000000000040447e _start()  ???:0
=================================
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 3067957 on node n001 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
2 total processes killed (some possibly by mpiexec during cleanup)
Command exited with non-zero status 139
	Command being timed: "mpiexec -n 8 ./code_parallel/build/apps/run_full_code.parallel"
	User time (seconds): 0.14
	System time (seconds): 0.14
	Percent of CPU this job got: 52%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.55
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 45036
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 267
	Minor (reclaiming a frame) page faults: 15712
	Voluntary context switches: 1471
	Involuntary context switches: 33
	Swaps: 0
	File system inputs: 0
	File system outputs: 8
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 139
